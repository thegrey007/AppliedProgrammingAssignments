{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63ae3c3-66de-478a-b704-dbbf4a824d17",
   "metadata": {},
   "source": [
    "#### The zip folder contains the original jupyter notebook (.ipynb), which can be executed either on local jupyter or on this server. It also contains the exported LaTeX version of the notebook, and the data files. I have made use of numpy, cmath and sys libraries in this notebook. I have also made use of the deque class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308b886-4158-46d4-869a-3f06ded3f1c4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456b7e3a-8cc8-4c42-bc4d-f60f6e2b4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cmath\n",
    "import sys\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ba036-f622-403f-8d8b-c796a4c0e051",
   "metadata": {
    "tags": []
   },
   "source": [
    "# c8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e87b71-d657-482a-b9c3-70cf7bc0c5ab",
   "metadata": {},
   "source": [
    "## Reading input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2886607d-beed-4d8d-9bdf-140fbfb1c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"c8.netlist\", \"r\") \n",
    "input0 = f.readlines() # reading the netlist line by line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79492c9-e6e8-4398-b8bd-7ce15082316e",
   "metadata": {},
   "source": [
    "## Constructing the graph and checking for cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0438cd9d-d9cc-4324-a818-9a3d79241596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# create a DAG\n",
    "g = nx.DiGraph()\n",
    "inputdict = {}\n",
    "gateprop = {}\n",
    "\n",
    "for line in input0:\n",
    "    tokens = line.split() # split into list of individual inputs \n",
    "    if (tokens[1] != 'inv') and (tokens[1] != 'buf'):\n",
    "        if tokens[2] not in gateprop: # gateprop is a dictionary that has a node as key and has a list of all its successors as value\n",
    "            gateprop[tokens[2]] = []\n",
    "        if tokens[3] not in gateprop:\n",
    "            gateprop[tokens[3]] = []\n",
    "        gateprop[tokens[2]].append(tokens[4])\n",
    "        gateprop[tokens[3]].append(tokens[4])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[4]}\"), (f\"{tokens[3]}\", f\"{tokens[4]}\")]) # creating edges of the directed acyclic graph\n",
    "        inputdict[f\"{tokens[4]}\"] = [f\"{tokens[2]}\", f\"{tokens[3]}\", f\"{tokens[1]}\"] # creating an input ddictionary which has node name as key and a list of its inputs and gate type as value\n",
    "    else:\n",
    "        if tokens[2] not in gateprop:\n",
    "            gateprop[tokens[2]] = []\n",
    "        gateprop[tokens[2]].append(tokens[3])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[3]}\")])\n",
    "        inputdict[f\"{tokens[3]}\"] = [f\"{tokens[2]}\", f\"{tokens[1]}\"] # creating input dictionary for not and buffer gates\n",
    "        \n",
    "# print(gateprop)\n",
    "if not nx.is_directed_acyclic_graph(g): # checking if graph has cycle; if cyclic, exit, since evaluation not possible\n",
    "    print(\"Cycle in graph!\")\n",
    "    sys.exit()\n",
    "nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "alpha = sorted(nl) # nodes in alphabetical order, used for future file writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f2c20-8a21-47c4-8fb9-40fb91b67cf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Topological sort evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87441588-4f2e-4a48-a8b8-f95572d41d13",
   "metadata": {},
   "source": [
    "First, we read the input from the file and initialize `outputdict` to an empty dictionary for storing steady state outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906e7d7a-9ecb-4613-831b-da716cb7f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdict = {} # output dictionary which has keys as nodes and their final steady state values as values.\n",
    "\n",
    "f = open(\"c8.inputs\", \"r\") \n",
    "inp = f.readlines()\n",
    "f.close()\n",
    "\n",
    "nodeorder = inp[0].split() # order of input nodes in the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2a84fb-1570-42c9-b24f-cbe5fc170fd8",
   "metadata": {},
   "source": [
    "Next, we define `topoeval` which sorts the given nodes in topological order, evaluates the nodes in this order and stores the outputs in `outputdict`. Finally, it writes these steady state values to the output file, `topooutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e318462-16f6-4bae-800f-f83c75edcf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoeval(inp):\n",
    "    nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "    ft = open(\"topooutput8.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        ft.write(f\"{node} \") # first row of file has alphabetically ordered node names\n",
    "    ft.write(\"\\n\")\n",
    "    for line in inp:\n",
    "        tok = line.split() \n",
    "        if tok == nodeorder: # skipping over the first line since it just gives column names\n",
    "            continue\n",
    "        for i in range(len(tok)):\n",
    "            outputdict[f\"{nodeorder[i]}\"] = int(tok[i]) # initializing primary inputs from the given inputs file\n",
    "        for i in range(len(nl)):\n",
    "            if nl[i] not in inputdict: # if it is a primary input, then continue; final value is already in outputdict, nothing to evaluate\n",
    "                continue\n",
    "            if inputdict[nl[i]][1] == 'inv': # checking the gate value of each input and calculating the steady state output accordingly\n",
    "                outputdict[nl[i]] = int(not(outputdict[(inputdict[nl[i]][0])]))\n",
    "            elif inputdict[nl[i]][1] == 'buf':\n",
    "                outputdict[nl[i]] = int((outputdict[(inputdict[nl[i]][0])]))\n",
    "            else: \n",
    "                gate = inputdict[nl[i]][2]\n",
    "                a = outputdict[inputdict[nl[i]][0]]\n",
    "                b = outputdict[inputdict[nl[i]][1]]\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[nl[i]] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[nl[i]] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[nl[i]] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[nl[i]] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[nl[i]] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[nl[i]] = int(not((a and (not b)) or (b and (not a))))\n",
    "        for node in alpha:\n",
    "            ft.write(f\"{outputdict[node]} \")\n",
    "        ft.write(\"\\n\")\n",
    "    ft.close()\n",
    "    # return(outputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e5ffb8-8271-454f-a514-fa2cc11108e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42 ms ± 74.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "topoeval(inp)\n",
    "%timeit topoeval(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c76cd-dfd7-4ee4-8053-49aa8b0e3aeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gate driven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcd99f-0f52-4beb-b9c1-007a66f3259d",
   "metadata": {},
   "source": [
    "Since we have already read the input file and initialized the output dictionary, we directly start by defining our function, `gatedriven`.\n",
    "\n",
    "This function first reads in the input line by line, and for each new line, we check each input against its previous value. If an input has changed from its previous value, we update it in `outputdict` and add all its immediate successors to the processing queue (since they may change due to the change in this node). \n",
    "\n",
    "We then process this queue until it is empty. We evaluate the element at the top of the queue, and if it changes from its previously known output, then add its successors to the processing queue.\n",
    "Finally, we write the values of `outputdict` to the output file, `gateoutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e108cd0a-32bf-46d2-b42e-7a7465cb4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedriven(inp1):\n",
    "    f1 = open(\"gateoutput8.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        f1.write(node + \" \") # first line is node names in alphabetical order\n",
    "    f1.write(\"\\n\")\n",
    "    previnp = [\"x\" for i in range(len(alpha))] # initialize previous input to garbage values initially\n",
    "\n",
    "    task = deque()\n",
    "\n",
    "    for line in inp1:\n",
    "        vals = line.split()\n",
    "        for i in range(len(vals)):\n",
    "            if vals[i] != previnp[i]: # if any primary input changes..\n",
    "                outputdict[nodeorder[i]] = int(vals[i]) # update the new value of the input in the output dictionary, and...\n",
    "                for ele in gateprop[nodeorder[i]]: # add all its immediately connected outputs to the processing queue\n",
    "                    task.append(ele)\n",
    "                    # print(task.get())\n",
    "        previnp = vals # now, current input becomes previous input for the next iteration, so update it\n",
    "        while(bool(task)): # while the processing queue is not empty\n",
    "            currnode = task[0] # processing first element of the queue\n",
    "            try:\n",
    "                while(task[0] == currnode): # if multiple of the same node are added consecutively to the queue, pop them out; these are redundant, and will result in the same output\n",
    "                    task.popleft()\n",
    "            except:\n",
    "                pass\n",
    "            # print(currnode)\n",
    "            prevoutput = outputdict[currnode] # storing the value of the node before evaluating it for the changed inputs\n",
    "            if inputdict[currnode][1] == 'inv': # check the gate type and update steady state dictionary accordingly\n",
    "                outputdict[currnode] = int(not(outputdict[(inputdict[currnode][0])]))\n",
    "            elif inputdict[currnode][1] == 'buf':\n",
    "                outputdict[currnode] = int(outputdict[(inputdict[currnode][0])])\n",
    "            else:\n",
    "                gate = inputdict[currnode][2]\n",
    "                a = int(outputdict[inputdict[currnode][0]])\n",
    "                b = int(outputdict[inputdict[currnode][1]])\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[currnode] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[currnode] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[currnode] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[currnode] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[currnode] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[currnode] = int(not((a and (not b)) or (b and (not a))))\n",
    "            if prevoutput != outputdict[currnode]: # only add successors to the queue if the output has changed after processing this node again (from the queue)\n",
    "                try:\n",
    "                    for ele in gateprop[currnode]:\n",
    "                        task.append(ele)\n",
    "                except:\n",
    "                    pass\n",
    "        for node in alpha: # writing outputs for the current input to the file\n",
    "            f1.write(f\"{outputdict[node]} \")\n",
    "        f1.write(\"\\n\")\n",
    "        \n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5683d077-3929-42c5-87dc-de52f5c1ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71 ms ± 93.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "input1 = inp[1:]\n",
    "gatedriven(input1)\n",
    "%timeit gatedriven(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae441335-3cd4-43f3-8db5-2ee4b0e0d7d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# c17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c098b7e-ec7d-4e74-ba0f-ed40dbaaa370",
   "metadata": {},
   "source": [
    "## Reading input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726df9f1-4829-41ae-8249-2f9a318923a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"c17.netlist\", \"r\") \n",
    "input0 = f.readlines() # reading the netlist line by line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410220a9-4338-460b-ad52-fdfa1ba0ac00",
   "metadata": {},
   "source": [
    "## Constructing the graph and checking for cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac608f9a-d620-4633-a65c-ea0d0532250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# create a DAG\n",
    "g = nx.DiGraph()\n",
    "inputdict = {}\n",
    "gateprop = {}\n",
    "\n",
    "for line in input0:\n",
    "    tokens = line.split() # split into list of individual inputs \n",
    "    if (tokens[1] != 'inv') and (tokens[1] != 'buf'):\n",
    "        if tokens[2] not in gateprop: # gateprop is a dictionary that has a node as key and has a list of all its successors as value\n",
    "            gateprop[tokens[2]] = []\n",
    "        if tokens[3] not in gateprop:\n",
    "            gateprop[tokens[3]] = []\n",
    "        gateprop[tokens[2]].append(tokens[4])\n",
    "        gateprop[tokens[3]].append(tokens[4])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[4]}\"), (f\"{tokens[3]}\", f\"{tokens[4]}\")]) # creating edges of the directed acyclic graph\n",
    "        inputdict[f\"{tokens[4]}\"] = [f\"{tokens[2]}\", f\"{tokens[3]}\", f\"{tokens[1]}\"] # creating an input ddictionary which has node name as key and a list of its inputs and gate type as value\n",
    "    else:\n",
    "        if tokens[2] not in gateprop:\n",
    "            gateprop[tokens[2]] = []\n",
    "        gateprop[tokens[2]].append(tokens[3])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[3]}\")])\n",
    "        inputdict[f\"{tokens[3]}\"] = [f\"{tokens[2]}\", f\"{tokens[1]}\"] # creating input dictionary for not and buffer gates\n",
    "        \n",
    "# print(gateprop)\n",
    "if not nx.is_directed_acyclic_graph(g): # checking if graph has cycle; if cyclic, exit, since evaluation not possible\n",
    "    print(\"Cycle in graph!\")\n",
    "    sys.exit()\n",
    "nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "alpha = sorted(nl) # nodes in alphabetical order, used for future file writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7982624-59a3-4f0e-bc26-674440d47f2a",
   "metadata": {},
   "source": [
    "# Topological sort evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d583b3-75c7-4038-a9fa-f70648fc2e48",
   "metadata": {},
   "source": [
    "First, we read the input from the file and initialize `outputdict` to an empty dictionary for storing steady state outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd7107c-d7d8-46c6-90be-b1d777fe8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdict = {} # output dictionary which has keys as nodes and their final steady state values as values.\n",
    "\n",
    "f = open(\"c17.inputs\", \"r\") \n",
    "inp = f.readlines()\n",
    "f.close()\n",
    "\n",
    "nodeorder = inp[0].split() # order of input nodes in the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbc928-eecb-4e71-b25f-67006f517b98",
   "metadata": {},
   "source": [
    "Next, we define `topoeval` which sorts the given nodes in topological order, evaluates the nodes in this order and stores the outputs in `outputdict`. Finally, it writes these steady state values to the output file, `topooutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126b8635-71f9-4646-b007-6a74762a98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoeval(inp):\n",
    "    nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "    ft = open(\"topooutput17.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        ft.write(f\"{node} \") # first row of file has alphabetically ordered node names\n",
    "    ft.write(\"\\n\")\n",
    "    for line in inp:\n",
    "        tok = line.split() \n",
    "        if tok == nodeorder: # skipping over the first line since it just gives column names\n",
    "            continue\n",
    "        for i in range(len(tok)):\n",
    "            outputdict[f\"{nodeorder[i]}\"] = int(tok[i]) # initializing primary inputs from the given inputs file\n",
    "        for i in range(len(nl)):\n",
    "            if nl[i] not in inputdict: # if it is a primary input, then continue; final value is already in outputdict, nothing to evaluate\n",
    "                continue\n",
    "            if inputdict[nl[i]][1] == 'inv': # checking the gate value of each input and calculating the steady state output accordingly\n",
    "                outputdict[nl[i]] = int(not(outputdict[(inputdict[nl[i]][0])]))\n",
    "            elif inputdict[nl[i]][1] == 'buf':\n",
    "                outputdict[nl[i]] = int((outputdict[(inputdict[nl[i]][0])]))\n",
    "            else: \n",
    "                gate = inputdict[nl[i]][2]\n",
    "                a = outputdict[inputdict[nl[i]][0]]\n",
    "                b = outputdict[inputdict[nl[i]][1]]\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[nl[i]] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[nl[i]] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[nl[i]] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[nl[i]] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[nl[i]] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[nl[i]] = int(not((a and (not b)) or (b and (not a))))\n",
    "        for node in alpha:\n",
    "            ft.write(f\"{outputdict[node]} \")\n",
    "        ft.write(\"\\n\")\n",
    "    ft.close()\n",
    "    # return(outputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e62f3d-31c8-4061-a176-652ad2184227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867 µs ± 17.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "topoeval(inp)\n",
    "%timeit topoeval(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386b2d7-facc-424a-9642-153dd390bcf8",
   "metadata": {},
   "source": [
    "# Gate driven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89781d6-71f9-4bfb-82c8-08559209b942",
   "metadata": {},
   "source": [
    "Since we have already read the input file and initialized the output dictionary, we directly start by defining our function, `gatedriven`.\n",
    "\n",
    "This function first reads in the input line by line, and for each new line, we check each input against its previous value. If an input has changed from its previous value, we update it in `outputdict` and add all its immediate successors to the processing queue (since they may change due to the change in this node). \n",
    "\n",
    "We then process this queue until it is empty. We evaluate the element at the top of the queue, and if it changes from its previously known output, then add its successors to the processing queue.\n",
    "Finally, we write the values of `outputdict` to the output file, `gateoutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438e3b92-18e0-4359-b9fd-ab65327bd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedriven(inp1):\n",
    "    f1 = open(\"gateoutput17.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        f1.write(node + \" \") # first line is node names in alphabetical order\n",
    "    f1.write(\"\\n\")\n",
    "    previnp = [\"x\" for i in range(len(alpha))] # initialize previous input to garbage values initially\n",
    "\n",
    "    task = deque()\n",
    "\n",
    "    for line in inp1:\n",
    "        vals = line.split()\n",
    "        for i in range(len(vals)):\n",
    "            if vals[i] != previnp[i]: # if any primary input changes..\n",
    "                outputdict[nodeorder[i]] = int(vals[i]) # update the new value of the input in the output dictionary, and...\n",
    "                for ele in gateprop[nodeorder[i]]: # add all its immediately connected outputs to the processing queue\n",
    "                    task.append(ele)\n",
    "                    # print(task.get())\n",
    "        previnp = vals # now, current input becomes previous input for the next iteration, so update it\n",
    "        while(bool(task)): # while the processing queue is not empty\n",
    "            currnode = task[0] # processing first element of the queue\n",
    "            try:\n",
    "                while(task[0] == currnode): # if multiple of the same node are added consecutively to the queue, pop them out; these are redundant, and will result in the same output\n",
    "                    task.popleft()\n",
    "            except:\n",
    "                pass\n",
    "            # print(currnode)\n",
    "            prevoutput = outputdict[currnode] # storing the value of the node before evaluating it for the changed inputs\n",
    "            if inputdict[currnode][1] == 'inv': # check the gate type and update steady state dictionary accordingly\n",
    "                outputdict[currnode] = int(not(outputdict[(inputdict[currnode][0])]))\n",
    "            elif inputdict[currnode][1] == 'buf':\n",
    "                outputdict[currnode] = int(outputdict[(inputdict[currnode][0])])\n",
    "            else:\n",
    "                gate = inputdict[currnode][2]\n",
    "                a = int(outputdict[inputdict[currnode][0]])\n",
    "                b = int(outputdict[inputdict[currnode][1]])\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[currnode] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[currnode] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[currnode] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[currnode] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[currnode] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[currnode] = int(not((a and (not b)) or (b and (not a))))\n",
    "            if prevoutput != outputdict[currnode]: # only add successors to the queue if the output has changed after processing this node again (from the queue)\n",
    "                try:\n",
    "                    for ele in gateprop[currnode]:\n",
    "                        task.append(ele)\n",
    "                except:\n",
    "                    pass\n",
    "        for node in alpha: # writing outputs for the current input to the file\n",
    "            f1.write(f\"{outputdict[node]} \")\n",
    "        f1.write(\"\\n\")\n",
    "        \n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf9a6d8-fc36-474a-9d76-933f80794957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919 µs ± 30 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "input1 = inp[1:]\n",
    "gatedriven(input1)\n",
    "%timeit gatedriven(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125c4f0-c498-424d-828c-a001d2744cc1",
   "metadata": {},
   "source": [
    "# c17_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de357df-1435-4c0b-93be-1ed70ce80511",
   "metadata": {},
   "source": [
    "## Reading input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9fb124-91af-414f-9a53-06c8de74ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"c17_1.netlist\", \"r\") \n",
    "input0 = f.readlines() # reading the netlist line by line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4cf95-e051-416c-be63-d3648d08f113",
   "metadata": {},
   "source": [
    "## Constructing the graph and checking for cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f096f6-1c03-4ac7-932d-755df46ba04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle in graph!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "# create a DAG\n",
    "g = nx.DiGraph()\n",
    "inputdict = {}\n",
    "gateprop = {}\n",
    "\n",
    "for line in input0:\n",
    "    tokens = line.split() # split into list of individual inputs \n",
    "    if (tokens[1] != 'inv') and (tokens[1] != 'buf'):\n",
    "        if tokens[2] not in gateprop: # gateprop is a dictionary that has a node as key and has a list of all its successors as value\n",
    "            gateprop[tokens[2]] = []\n",
    "        if tokens[3] not in gateprop:\n",
    "            gateprop[tokens[3]] = []\n",
    "        gateprop[tokens[2]].append(tokens[4])\n",
    "        gateprop[tokens[3]].append(tokens[4])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[4]}\"), (f\"{tokens[3]}\", f\"{tokens[4]}\")]) # creating edges of the directed acyclic graph\n",
    "        inputdict[f\"{tokens[4]}\"] = [f\"{tokens[2]}\", f\"{tokens[3]}\", f\"{tokens[1]}\"] # creating an input ddictionary which has node name as key and a list of its inputs and gate type as value\n",
    "    else:\n",
    "        if tokens[2] not in gateprop:\n",
    "            gateprop[tokens[2]] = []\n",
    "        gateprop[tokens[2]].append(tokens[3])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[3]}\")])\n",
    "        inputdict[f\"{tokens[3]}\"] = [f\"{tokens[2]}\", f\"{tokens[1]}\"] # creating input dictionary for not and buffer gates\n",
    "        \n",
    "# print(gateprop)\n",
    "if not nx.is_directed_acyclic_graph(g): # checking if graph has cycle; if cyclic, exit, since evaluation not possible\n",
    "    print(\"Cycle in graph!\")\n",
    "    sys.exit()\n",
    "nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "alpha = sorted(nl) # nodes in alphabetical order, used for future file writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01718676-827b-420e-ac68-250004e5929a",
   "metadata": {},
   "source": [
    "As we can see, there is a cycle in the graph, so not possible to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0cbc2-8e0e-447f-9742-4deb7b3b20a8",
   "metadata": {},
   "source": [
    "# c432\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf2b95-d494-4eb0-910c-6df93b0b5074",
   "metadata": {},
   "source": [
    "## Reading input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87729d1-86f2-4110-90c9-ec5bbf06fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"c432.netlist\", \"r\") \n",
    "input0 = f.readlines() # reading the netlist line by line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c819bf9-8667-40c3-9687-b34ee431feb7",
   "metadata": {},
   "source": [
    "## Constructing the graph and checking for cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f4bb4ef-5f23-4479-be79-3b2533306076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# create a DAG\n",
    "g = nx.DiGraph()\n",
    "inputdict = {}\n",
    "gateprop = {}\n",
    "\n",
    "for line in input0:\n",
    "    tokens = line.split() # split into list of individual inputs \n",
    "    if (tokens[1] != 'inv') and (tokens[1] != 'buf'):\n",
    "        if tokens[2] not in gateprop: # gateprop is a dictionary that has a node as key and has a list of all its successors as value\n",
    "            gateprop[tokens[2]] = []\n",
    "        if tokens[3] not in gateprop:\n",
    "            gateprop[tokens[3]] = []\n",
    "        gateprop[tokens[2]].append(tokens[4])\n",
    "        gateprop[tokens[3]].append(tokens[4])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[4]}\"), (f\"{tokens[3]}\", f\"{tokens[4]}\")]) # creating edges of the directed acyclic graph\n",
    "        inputdict[f\"{tokens[4]}\"] = [f\"{tokens[2]}\", f\"{tokens[3]}\", f\"{tokens[1]}\"] # creating an input ddictionary which has node name as key and a list of its inputs and gate type as value\n",
    "    else:\n",
    "        if tokens[2] not in gateprop:\n",
    "            gateprop[tokens[2]] = []\n",
    "        gateprop[tokens[2]].append(tokens[3])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[3]}\")])\n",
    "        inputdict[f\"{tokens[3]}\"] = [f\"{tokens[2]}\", f\"{tokens[1]}\"] # creating input dictionary for not and buffer gates\n",
    "        \n",
    "# print(gateprop)\n",
    "if not nx.is_directed_acyclic_graph(g): # checking if graph has cycle; if cyclic, exit, since evaluation not possible\n",
    "    print(\"Cycle in graph!\")\n",
    "    sys.exit()\n",
    "nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "alpha = sorted(nl) # nodes in alphabetical order, used for future file writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e2ead-6706-47e1-9764-17aa871006f2",
   "metadata": {},
   "source": [
    "# Topological sort evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d6d02-4fdd-46c1-b378-b7ba348b2845",
   "metadata": {},
   "source": [
    "First, we read the input from the file and initialize `outputdict` to an empty dictionary for storing steady state outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7de490c-4b1c-49dd-87dc-1281884ced15",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdict = {} # output dictionary which has keys as nodes and their final steady state values as values.\n",
    "\n",
    "f = open(\"c432.inputs\", \"r\") \n",
    "inp = f.readlines()\n",
    "f.close()\n",
    "\n",
    "nodeorder = inp[0].split() # order of input nodes in the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23e088-edf7-4dd6-a226-a46a9edbd583",
   "metadata": {},
   "source": [
    "Next, we define `topoeval` which sorts the given nodes in topological order, evaluates the nodes in this order and stores the outputs in `outputdict`. Finally, it writes these steady state values to the output file, `topooutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6be7609-be77-4c48-b602-5d5db1abf5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoeval(inp):\n",
    "    nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "    ft = open(\"topooutput432.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        ft.write(f\"{node} \") # first row of file has alphabetically ordered node names\n",
    "    ft.write(\"\\n\")\n",
    "    for line in inp:\n",
    "        tok = line.split() \n",
    "        if tok == nodeorder: # skipping over the first line since it just gives column names\n",
    "            continue\n",
    "        for i in range(len(tok)):\n",
    "            outputdict[f\"{nodeorder[i]}\"] = int(tok[i]) # initializing primary inputs from the given inputs file\n",
    "        for i in range(len(nl)):\n",
    "            if nl[i] not in inputdict: # if it is a primary input, then continue; final value is already in outputdict, nothing to evaluate\n",
    "                continue\n",
    "            if inputdict[nl[i]][1] == 'inv': # checking the gate value of each input and calculating the steady state output accordingly\n",
    "                outputdict[nl[i]] = int(not(outputdict[(inputdict[nl[i]][0])]))\n",
    "            elif inputdict[nl[i]][1] == 'buf':\n",
    "                outputdict[nl[i]] = int((outputdict[(inputdict[nl[i]][0])]))\n",
    "            else: \n",
    "                gate = inputdict[nl[i]][2]\n",
    "                a = outputdict[inputdict[nl[i]][0]]\n",
    "                b = outputdict[inputdict[nl[i]][1]]\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[nl[i]] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[nl[i]] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[nl[i]] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[nl[i]] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[nl[i]] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[nl[i]] = int(not((a and (not b)) or (b and (not a))))\n",
    "        for node in alpha:\n",
    "            ft.write(f\"{outputdict[node]} \")\n",
    "        ft.write(\"\\n\")\n",
    "    ft.close()\n",
    "    # return(outputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f49f03e-51c1-4e20-82cc-098631aad782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ms ± 817 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "topoeval(inp)\n",
    "%timeit topoeval(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c85656-d046-4966-ab80-cd09706c1b7d",
   "metadata": {},
   "source": [
    "# Gate driven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848de85-3766-425d-8678-9f03652bc6c8",
   "metadata": {},
   "source": [
    "Since we have already read the input file and initialized the output dictionary, we directly start by defining our function, `gatedriven`.\n",
    "\n",
    "This function first reads in the input line by line, and for each new line, we check each input against its previous value. If an input has changed from its previous value, we update it in `outputdict` and add all its immediate successors to the processing queue (since they may change due to the change in this node). \n",
    "\n",
    "We then process this queue until it is empty. We evaluate the element at the top of the queue, and if it changes from its previously known output, then add its successors to the processing queue.\n",
    "Finally, we write the values of `outputdict` to the output file, `gateoutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f0a73f7-0ac1-40d1-ae59-61cce40d8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedriven(inp1):\n",
    "    f1 = open(\"gateoutput432.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        f1.write(node + \" \") # first line is node names in alphabetical order\n",
    "    f1.write(\"\\n\")\n",
    "    previnp = [\"x\" for i in range(len(alpha))] # initialize previous input to garbage values initially\n",
    "\n",
    "    task = deque()\n",
    "\n",
    "    for line in inp1:\n",
    "        vals = line.split()\n",
    "        for i in range(len(vals)):\n",
    "            if vals[i] != previnp[i]: # if any primary input changes..\n",
    "                outputdict[nodeorder[i]] = int(vals[i]) # update the new value of the input in the output dictionary, and...\n",
    "                for ele in gateprop[nodeorder[i]]: # add all its immediately connected outputs to the processing queue\n",
    "                    task.append(ele)\n",
    "                    # print(task.get())\n",
    "        previnp = vals # now, current input becomes previous input for the next iteration, so update it\n",
    "        while(bool(task)): # while the processing queue is not empty\n",
    "            currnode = task[0] # processing first element of the queue\n",
    "            try:\n",
    "                while(task[0] == currnode): # if multiple of the same node are added consecutively to the queue, pop them out; these are redundant, and will result in the same output\n",
    "                    task.popleft()\n",
    "            except:\n",
    "                pass\n",
    "            # print(currnode)\n",
    "            prevoutput = outputdict[currnode] # storing the value of the node before evaluating it for the changed inputs\n",
    "            if inputdict[currnode][1] == 'inv': # check the gate type and update steady state dictionary accordingly\n",
    "                outputdict[currnode] = int(not(outputdict[(inputdict[currnode][0])]))\n",
    "            elif inputdict[currnode][1] == 'buf':\n",
    "                outputdict[currnode] = int(outputdict[(inputdict[currnode][0])])\n",
    "            else:\n",
    "                gate = inputdict[currnode][2]\n",
    "                a = int(outputdict[inputdict[currnode][0]])\n",
    "                b = int(outputdict[inputdict[currnode][1]])\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[currnode] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[currnode] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[currnode] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[currnode] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[currnode] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[currnode] = int(not((a and (not b)) or (b and (not a))))\n",
    "            if prevoutput != outputdict[currnode]: # only add successors to the queue if the output has changed after processing this node again (from the queue)\n",
    "                try:\n",
    "                    for ele in gateprop[currnode]:\n",
    "                        task.append(ele)\n",
    "                except:\n",
    "                    pass\n",
    "        for node in alpha: # writing outputs for the current input to the file\n",
    "            f1.write(f\"{outputdict[node]} \")\n",
    "        f1.write(\"\\n\")\n",
    "        \n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "237f7a60-c6d9-41cd-94a8-26559da78672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.8 ms ± 736 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "input1 = inp[1:]\n",
    "gatedriven(input1)\n",
    "%timeit gatedriven(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5625c8-b88f-4def-b817-3b3e91a14c76",
   "metadata": {},
   "source": [
    "## Reading input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb2d69-201d-46f0-a0a0-98e0179b2eb6",
   "metadata": {},
   "source": [
    "# parity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1709db-cd96-4146-9e84-2712fb60f00c",
   "metadata": {},
   "source": [
    "## Reading input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b2003cd-ad6e-48b5-99b1-d2a5046cb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"parity.netlist\", \"r\") \n",
    "input0 = f.readlines() # reading the netlist line by line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ebb480-9eb5-4f21-a264-238d15e2fe16",
   "metadata": {},
   "source": [
    "## Constructing the graph and checking for cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53aebd12-1a9d-4d3e-938e-7d4c7474f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# create a DAG\n",
    "g = nx.DiGraph()\n",
    "inputdict = {}\n",
    "gateprop = {}\n",
    "\n",
    "for line in input0:\n",
    "    tokens = line.split() # split into list of individual inputs \n",
    "    if (tokens[1] != 'inv') and (tokens[1] != 'buf'):\n",
    "        if tokens[2] not in gateprop: # gateprop is a dictionary that has a node as key and has a list of all its successors as value\n",
    "            gateprop[tokens[2]] = []\n",
    "        if tokens[3] not in gateprop:\n",
    "            gateprop[tokens[3]] = []\n",
    "        gateprop[tokens[2]].append(tokens[4])\n",
    "        gateprop[tokens[3]].append(tokens[4])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[4]}\"), (f\"{tokens[3]}\", f\"{tokens[4]}\")]) # creating edges of the directed acyclic graph\n",
    "        inputdict[f\"{tokens[4]}\"] = [f\"{tokens[2]}\", f\"{tokens[3]}\", f\"{tokens[1]}\"] # creating an input ddictionary which has node name as key and a list of its inputs and gate type as value\n",
    "    else:\n",
    "        if tokens[2] not in gateprop:\n",
    "            gateprop[tokens[2]] = []\n",
    "        gateprop[tokens[2]].append(tokens[3])\n",
    "        g.add_edges_from([(f\"{tokens[2]}\", f\"{tokens[3]}\")])\n",
    "        inputdict[f\"{tokens[3]}\"] = [f\"{tokens[2]}\", f\"{tokens[1]}\"] # creating input dictionary for not and buffer gates\n",
    "        \n",
    "# print(gateprop)\n",
    "if not nx.is_directed_acyclic_graph(g): # checking if graph has cycle; if cyclic, exit, since evaluation not possible\n",
    "    print(\"Cycle in graph!\")\n",
    "    sys.exit()\n",
    "nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "alpha = sorted(nl) # nodes in alphabetical order, used for future file writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5789c-7d3c-4db0-9d3d-f7d2a13301ac",
   "metadata": {},
   "source": [
    "# Topological sort evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592586cf-1e93-4a30-b029-ea61613cabe6",
   "metadata": {},
   "source": [
    "First, we read the input from the file and initialize `outputdict` to an empty dictionary for storing steady state outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc83b2f9-6503-48b5-892e-6aca04f4cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdict = {} # output dictionary which has keys as nodes and their final steady state values as values.\n",
    "\n",
    "f = open(\"parity.inputs\", \"r\") \n",
    "inp = f.readlines()\n",
    "f.close()\n",
    "\n",
    "nodeorder = inp[0].split() # order of input nodes in the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea34a0-b73b-42bd-b760-ad5645336081",
   "metadata": {},
   "source": [
    "Next, we define `topoeval` which sorts the given nodes in topological order, evaluates the nodes in this order and stores the outputs in `outputdict`. Finally, it writes these steady state values to the output file, `topooutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d023c5f-e1d5-4d37-b143-408d7f1ae23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoeval(inp):\n",
    "    nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "    ft = open(\"topooutputp.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        ft.write(f\"{node} \") # first row of file has alphabetically ordered node names\n",
    "    ft.write(\"\\n\")\n",
    "    for line in inp:\n",
    "        tok = line.split() \n",
    "        if tok == nodeorder: # skipping over the first line since it just gives column names\n",
    "            continue\n",
    "        for i in range(len(tok)):\n",
    "            outputdict[f\"{nodeorder[i]}\"] = int(tok[i]) # initializing primary inputs from the given inputs file\n",
    "        for i in range(len(nl)):\n",
    "            if nl[i] not in inputdict: # if it is a primary input, then continue; final value is already in outputdict, nothing to evaluate\n",
    "                continue\n",
    "            if inputdict[nl[i]][1] == 'inv': # checking the gate value of each input and calculating the steady state output accordingly\n",
    "                outputdict[nl[i]] = int(not(outputdict[(inputdict[nl[i]][0])]))\n",
    "            elif inputdict[nl[i]][1] == 'buf':\n",
    "                outputdict[nl[i]] = int((outputdict[(inputdict[nl[i]][0])]))\n",
    "            else: \n",
    "                gate = inputdict[nl[i]][2]\n",
    "                a = outputdict[inputdict[nl[i]][0]]\n",
    "                b = outputdict[inputdict[nl[i]][1]]\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[nl[i]] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[nl[i]] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[nl[i]] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[nl[i]] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[nl[i]] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[nl[i]] = int(not((a and (not b)) or (b and (not a))))\n",
    "        for node in alpha:\n",
    "            ft.write(f\"{outputdict[node]} \")\n",
    "        ft.write(\"\\n\")\n",
    "    ft.close()\n",
    "    # return(outputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75fe2f08-d194-4e84-b8e5-b82027cbf177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 µs ± 22.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "topoeval(inp)\n",
    "%timeit topoeval(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08a968-1bb0-463e-884e-4ea339ff4ade",
   "metadata": {},
   "source": [
    "# Gate driven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b7bdf-c9b4-48dd-bc04-7455711b44c4",
   "metadata": {},
   "source": [
    "Since we have already read the input file and initialized the output dictionary, we directly start by defining our function, `gatedriven`.\n",
    "\n",
    "This function first reads in the input line by line, and for each new line, we check each input against its previous value. If an input has changed from its previous value, we update it in `outputdict` and add all its immediate successors to the processing queue (since they may change due to the change in this node). \n",
    "\n",
    "We then process this queue until it is empty. We evaluate the element at the top of the queue, and if it changes from its previously known output, then add its successors to the processing queue.\n",
    "Finally, we write the values of `outputdict` to the output file, `gateoutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "892241c6-c52e-4483-bc6a-43280725bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedriven(inp1):\n",
    "    f1 = open(\"gateoutputp.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        f1.write(node + \" \") # first line is node names in alphabetical order\n",
    "    f1.write(\"\\n\")\n",
    "    previnp = [\"x\" for i in range(len(alpha))] # initialize previous input to garbage values initially\n",
    "\n",
    "    task = deque()\n",
    "\n",
    "    for line in inp1:\n",
    "        vals = line.split()\n",
    "        for i in range(len(vals)):\n",
    "            if vals[i] != previnp[i]: # if any primary input changes..\n",
    "                outputdict[nodeorder[i]] = int(vals[i]) # update the new value of the input in the output dictionary, and...\n",
    "                for ele in gateprop[nodeorder[i]]: # add all its immediately connected outputs to the processing queue\n",
    "                    task.append(ele)\n",
    "                    # print(task.get())\n",
    "        previnp = vals # now, current input becomes previous input for the next iteration, so update it\n",
    "        while(bool(task)): # while the processing queue is not empty\n",
    "            currnode = task[0] # processing first element of the queue\n",
    "            try:\n",
    "                while(task[0] == currnode): # if multiple of the same node are added consecutively to the queue, pop them out; these are redundant, and will result in the same output\n",
    "                    task.popleft()\n",
    "            except:\n",
    "                pass\n",
    "            # print(currnode)\n",
    "            prevoutput = outputdict[currnode] # storing the value of the node before evaluating it for the changed inputs\n",
    "            if inputdict[currnode][1] == 'inv': # check the gate type and update steady state dictionary accordingly\n",
    "                outputdict[currnode] = int(not(outputdict[(inputdict[currnode][0])]))\n",
    "            elif inputdict[currnode][1] == 'buf':\n",
    "                outputdict[currnode] = int(outputdict[(inputdict[currnode][0])])\n",
    "            else:\n",
    "                gate = inputdict[currnode][2]\n",
    "                a = int(outputdict[inputdict[currnode][0]])\n",
    "                b = int(outputdict[inputdict[currnode][1]])\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[currnode] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[currnode] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[currnode] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[currnode] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[currnode] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[currnode] = int(not((a and (not b)) or (b and (not a))))\n",
    "            if prevoutput != outputdict[currnode]: # only add successors to the queue if the output has changed after processing this node again (from the queue)\n",
    "                try:\n",
    "                    for ele in gateprop[currnode]:\n",
    "                        task.append(ele)\n",
    "                except:\n",
    "                    pass\n",
    "        for node in alpha: # writing outputs for the current input to the file\n",
    "            f1.write(f\"{outputdict[node]} \")\n",
    "        f1.write(\"\\n\")\n",
    "        \n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d6dfd47-9473-429e-a2b3-64337267d991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 µs ± 74.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "input1 = inp[1:]\n",
    "gatedriven(input1)\n",
    "%timeit gatedriven(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fecbb40-fb3f-4220-a3d6-0088f3964e23",
   "metadata": {},
   "source": [
    "# Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87435dc-a307-4b38-b812-3921faca06db",
   "metadata": {},
   "source": [
    "As we can see, the topological sort is faster in all the cases. \n",
    "This could possibly be because the event driven approach is optimal in cases where the number of changes in the inputs for consecutive time stamps is small. \n",
    "\n",
    "However, this is not the case for our inputs, since a significant number of inputs change for consecutive time stamps, which would increase redundancy in queueing and evaluation. However, the topo sort evaluates each node only once in any case. This is why event driven is slower than topo sort for our inputs, since we evaluate each node too many times.\n",
    "\n",
    "One way to solve this problem would be to optimize the event driven inputs by preprocessing them, and arranging the inputs such that consecutive inputs have the maximum similarity, i.e. the least number of input changes. This would reduce the queue size and redundant evaluation, thus significantly speeding up the event driven approach.\n",
    "\n",
    "Overall, event driven would be faster for more similar inputs (ie less changes in consecutive input lines), whereas for significantly dissimilar inputs, topological sort reduces redundancy, and hence, is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "635525ac-d62a-4b7b-ba9d-76641afdcb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"c17.netlist\", \"r\") \n",
    "input0 = f.readlines() # reading the netlist line by line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980368f6-9d1d-4a23-b881-0f62566acc07",
   "metadata": {},
   "source": [
    "First, we read the input from the file and initialize `outputdict` to an empty dictionary for storing steady state outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17caaa8-9e8c-4f27-baba-8536e6ceb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdict = {} # output dictionary which has keys as nodes and their final steady state values as values.\n",
    "\n",
    "f = open(\"c17inputs.txt\", \"r\") \n",
    "inp = f.readlines()\n",
    "f.close()\n",
    "\n",
    "nodeorder = inp[0].split() # order of input nodes in the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3569ee-5519-49cf-970c-6150fa118993",
   "metadata": {},
   "source": [
    "Next, we define `topoeval` which sorts the given nodes in topological order, evaluates the nodes in this order and stores the outputs in `outputdict`. Finally, it writes these steady state values to the output file, `topooutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed65622-5738-45b3-8efb-881ad2e5459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoeval(inp):\n",
    "    nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "    ft = open(\"topooutput.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        ft.write(f\"{node} \") # first row of file has alphabetically ordered node names\n",
    "    ft.write(\"\\n\")\n",
    "    for line in inp:\n",
    "        tok = line.split() \n",
    "        if tok == nodeorder: # skipping over the first line since it just gives column names\n",
    "            continue\n",
    "        for i in range(len(tok)):\n",
    "            outputdict[f\"{nodeorder[i]}\"] = int(tok[i]) # initializing primary inputs from the given inputs file\n",
    "        for i in range(len(nl)):\n",
    "            if nl[i] not in inputdict: # if it is a primary input, then continue; final value is already in outputdict, nothing to evaluate\n",
    "                continue\n",
    "            if inputdict[nl[i]][1] == 'inv': # checking the gate value of each input and calculating the steady state output accordingly\n",
    "                outputdict[nl[i]] = int(not(outputdict[(inputdict[nl[i]][0])]))\n",
    "            elif inputdict[nl[i]][1] == 'buf':\n",
    "                outputdict[nl[i]] = int((outputdict[(inputdict[nl[i]][0])]))\n",
    "            else: \n",
    "                gate = inputdict[nl[i]][2]\n",
    "                a = outputdict[inputdict[nl[i]][0]]\n",
    "                b = outputdict[inputdict[nl[i]][1]]\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[nl[i]] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[nl[i]] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[nl[i]] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[nl[i]] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[nl[i]] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[nl[i]] = int(not((a and (not b)) or (b and (not a))))\n",
    "        for node in alpha:\n",
    "            ft.write(f\"{outputdict[node]} \")\n",
    "        ft.write(\"\\n\")\n",
    "    ft.close()\n",
    "    # return(outputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c4d0d-03ef-4cb1-976a-1fb17bf22b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topoeval(inp)\n",
    "%timeit topoeval(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3514c09-1097-4c75-be5b-525b78ae867a",
   "metadata": {},
   "source": [
    "Since we have already read the input file and initialized the output dictionary, we directly start by defining our function, `gatedriven`.\n",
    "\n",
    "This function first reads in the input line by line, and for each new line, we check each input against its previous value. If an input has changed from its previous value, we update it in `outputdict` and add all its immediate successors to the processing queue (since they may change due to the change in this node). \n",
    "\n",
    "We then process this queue until it is empty. We evaluate the element at the top of the queue, and if it changes from its previously known output, then add its successors to the processing queue.\n",
    "Finally, we write the values of `outputdict` to the output file, `gateoutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e326569-6618-479f-8f06-ba3b4d7c37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedriven(inp1):\n",
    "    f1 = open(\"gateoutput.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        f1.write(node + \" \") # first line is node names in alphabetical order\n",
    "    f1.write(\"\\n\")\n",
    "    previnp = [\"x\" for i in range(len(alpha))] # initialize previous input to garbage values initially\n",
    "\n",
    "    task = deque()\n",
    "\n",
    "    for line in inp1:\n",
    "        vals = line.split()\n",
    "        for i in range(len(vals)):\n",
    "            if vals[i] != previnp[i]: # if any primary input changes..\n",
    "                outputdict[nodeorder[i]] = int(vals[i]) # update the new value of the input in the output dictionary, and...\n",
    "                for ele in gateprop[nodeorder[i]]: # add all its immediately connected outputs to the processing queue\n",
    "                    task.append(ele)\n",
    "                    # print(task.get())\n",
    "        previnp = vals # now, current input becomes previous input for the next iteration, so update it\n",
    "        while(bool(task)): # while the processing queue is not empty\n",
    "            currnode = task[0] # processing first element of the queue\n",
    "            try:\n",
    "                while(task[0] == currnode): # if multiple of the same node are added consecutively to the queue, pop them out; these are redundant, and will result in the same output\n",
    "                    task.popleft()\n",
    "            except:\n",
    "                pass\n",
    "            # print(currnode)\n",
    "            prevoutput = outputdict[currnode] # storing the value of the node before evaluating it for the changed inputs\n",
    "            if inputdict[currnode][1] == 'inv': # check the gate type and update steady state dictionary accordingly\n",
    "                outputdict[currnode] = int(not(outputdict[(inputdict[currnode][0])]))\n",
    "            elif inputdict[currnode][1] == 'buf':\n",
    "                outputdict[currnode] = int(outputdict[(inputdict[currnode][0])])\n",
    "            else:\n",
    "                gate = inputdict[currnode][2]\n",
    "                a = int(outputdict[inputdict[currnode][0]])\n",
    "                b = int(outputdict[inputdict[currnode][1]])\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[currnode] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[currnode] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[currnode] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[currnode] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[currnode] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[currnode] = int(not((a and (not b)) or (b and (not a))))\n",
    "            if prevoutput != outputdict[currnode]: # only add successors to the queue if the output has changed after processing this node again (from the queue)\n",
    "                try:\n",
    "                    for ele in gateprop[currnode]:\n",
    "                        task.append(ele)\n",
    "                except:\n",
    "                    pass\n",
    "        for node in alpha: # writing outputs for the current input to the file\n",
    "            f1.write(f\"{outputdict[node]} \")\n",
    "        f1.write(\"\\n\")\n",
    "        \n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3a5ae-73b5-486b-96a5-39d32921541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = inp[1:]\n",
    "gatedriven(input1)\n",
    "%timeit gatedriven(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666392ed-8055-4d5e-8bf8-d79890d8ea88",
   "metadata": {},
   "source": [
    "First, we read the input from the file and initialize `outputdict` to an empty dictionary for storing steady state outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60728b-d228-4f9f-9c63-5cc9fde011d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdict = {} # output dictionary which has keys as nodes and their final steady state values as values.\n",
    "\n",
    "f = open(\"c17inputs.txt\", \"r\") \n",
    "inp = f.readlines()\n",
    "f.close()\n",
    "\n",
    "nodeorder = inp[0].split() # order of input nodes in the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc744b-bb0c-49db-aa06-b0e8b08649fc",
   "metadata": {},
   "source": [
    "Next, we define `topoeval` which sorts the given nodes in topological order, evaluates the nodes in this order and stores the outputs in `outputdict`. Finally, it writes these steady state values to the output file, `topooutput.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa10f32-7d4d-4cb3-ac70-a0aba43662b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoeval(inp):\n",
    "    nl = list(nx.topological_sort(g)) # sorting the nodes in topological order\n",
    "    ft = open(\"topooutput.txt\", \"w\") # file to write output to \n",
    "    for node in alpha:\n",
    "        ft.write(f\"{node} \") # first row of file has alphabetically ordered node names\n",
    "    ft.write(\"\\n\")\n",
    "    for line in inp:\n",
    "        tok = line.split() \n",
    "        if tok == nodeorder: # skipping over the first line since it just gives column names\n",
    "            continue\n",
    "        for i in range(len(tok)):\n",
    "            outputdict[f\"{nodeorder[i]}\"] = int(tok[i]) # initializing primary inputs from the given inputs file\n",
    "        for i in range(len(nl)):\n",
    "            if nl[i] not in inputdict: # if it is a primary input, then continue; final value is already in outputdict, nothing to evaluate\n",
    "                continue\n",
    "            if inputdict[nl[i]][1] == 'inv': # checking the gate value of each input and calculating the steady state output accordingly\n",
    "                outputdict[nl[i]] = int(not(outputdict[(inputdict[nl[i]][0])]))\n",
    "            elif inputdict[nl[i]][1] == 'buf':\n",
    "                outputdict[nl[i]] = int((outputdict[(inputdict[nl[i]][0])]))\n",
    "            else: \n",
    "                gate = inputdict[nl[i]][2]\n",
    "                a = outputdict[inputdict[nl[i]][0]]\n",
    "                b = outputdict[inputdict[nl[i]][1]]\n",
    "                if gate == 'nand2':\n",
    "                    outputdict[nl[i]] = int(not(a and b))\n",
    "                elif gate == 'and2':\n",
    "                    outputdict[nl[i]] = int(a and b)\n",
    "                elif gate == 'or2':\n",
    "                    outputdict[nl[i]] = int(a or b)\n",
    "                elif gate == 'nor2':\n",
    "                    outputdict[nl[i]] = int(not(a or b))\n",
    "                elif gate == 'xor2':\n",
    "                    outputdict[nl[i]] = int((a and (not b)) or (b and (not a)))\n",
    "                elif gate == 'xnor2':\n",
    "                    outputdict[nl[i]] = int(not((a and (not b)) or (b and (not a))))\n",
    "        for node in alpha:\n",
    "            ft.write(f\"{outputdict[node]} \")\n",
    "        ft.write(\"\\n\")\n",
    "    ft.close()\n",
    "    # return(outputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f2346-f64e-4808-af5c-de7c965dd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "topoeval(inp)\n",
    "%timeit topoeval(inp)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Shreya .S. Ramanujam EE21B126"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
